# ğŸ”¥ PyTorchå®æˆ˜æŒ‡å—

## ğŸ“– æœ¬ç« å¯¼è¯»
PyTorchæ˜¯æ·±åº¦å­¦ä¹ é¢†åŸŸæœ€æµè¡Œçš„æ¡†æ¶ä¹‹ä¸€ï¼Œä½œä¸ºAIæµ‹è¯•å¼€å‘å·¥ç¨‹å¸ˆï¼Œç†è§£PyTorchèƒ½å¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£æ¨¡å‹å†…éƒ¨å·¥ä½œåŸç†ï¼Œä»è€Œè®¾è®¡æ›´æœ‰æ•ˆçš„æµ‹è¯•æ–¹æ¡ˆã€‚

## ğŸ¯ ä¸ºä»€ä¹ˆæµ‹è¯•å·¥ç¨‹å¸ˆéœ€è¦å­¦PyTorchï¼Ÿ

### ä¼ ç»Ÿæµ‹è¯• vs AIæ¨¡å‹æµ‹è¯•çš„å·®å¼‚

| æµ‹è¯•å¯¹è±¡ | éœ€è¦äº†è§£çš„ç¨‹åº¦ | åŸå›  |
|---------|---------------|------|
| ä¼ ç»Ÿè½¯ä»¶ | æ¥å£å’ŒåŠŸèƒ½ | é»‘ç›’æµ‹è¯•è¶³å¤Ÿ |
| AIæ¨¡å‹ | æ¨¡å‹æ¶æ„å’ŒåŸç† | éœ€è¦ç†è§£æ¦‚ç‡æ€§è¾“å‡º |

### å…·ä½“åº”ç”¨åœºæ™¯
1. **æ¨¡å‹åŠ è½½å’Œæ¨ç†**: æµ‹è¯•æ—¶éœ€è¦è°ƒç”¨æ¨¡å‹æ¥å£
2. **ç‰¹å¾æå–**: ç†è§£è¾“å…¥æ•°æ®çš„å¤„ç†è¿‡ç¨‹
3. **è°ƒè¯•åˆ†æ**: å½“æµ‹è¯•å‘ç°é—®é¢˜æ—¶ï¼Œéœ€è¦æ·±å…¥åˆ†æ
4. **è‡ªå®šä¹‰è¯„æµ‹**: å¼€å‘ç‰¹å®šçš„è¯„æµ‹å·¥å…·

## ğŸ§© PyTorchæ ¸å¿ƒæ¦‚å¿µ

### 1. å¼ é‡ (Tensor)
**ä»€ä¹ˆæ˜¯å¼ é‡**: å¤šç»´æ•°ç»„ï¼ŒPyTorchçš„åŸºæœ¬æ•°æ®ç»“æ„

**å¤§ç™½è¯ç†è§£**: 
- æ ‡é‡ï¼ˆ0ç»´ï¼‰: å•ä¸ªæ•°å­—ï¼Œå¦‚ `3.14`
- å‘é‡ï¼ˆ1ç»´ï¼‰: ä¸€åˆ—æ•°å­—ï¼Œå¦‚ `[1, 2, 3]`
- çŸ©é˜µï¼ˆ2ç»´ï¼‰: è¡¨æ ¼æ•°æ®ï¼Œå¦‚ `[[1,2], [3,4]]`
- å¼ é‡ï¼ˆnç»´ï¼‰: æ›´é«˜ç»´åº¦çš„æ•°ç»„

**ä»£ç ç¤ºä¾‹**:
```python
import torch

# åˆ›å»ºå¼ é‡
scalar = torch.tensor(3.14)          # æ ‡é‡
vector = torch.tensor([1, 2, 3])     # å‘é‡  
matrix = torch.tensor([[1,2], [3,4]]) # çŸ©é˜µ
3d_tensor = torch.randn(2, 3, 4)     # 3ç»´å¼ é‡

print(f"æ ‡é‡å½¢çŠ¶: {scalar.shape}")    # torch.Size([])
print(f"å‘é‡å½¢çŠ¶: {vector.shape}")    # torch.Size([3])
print(f"çŸ©é˜µå½¢çŠ¶: {matrix.shape}")    # torch.Size([2, 2])
print(f"3Då¼ é‡å½¢çŠ¶: {3d_tensor.shape}") # torch.Size([2, 3, 4])
```

### 2. è‡ªåŠ¨å¾®åˆ† (Autograd)
**ä»€ä¹ˆæ˜¯è‡ªåŠ¨å¾®åˆ†**: è‡ªåŠ¨è®¡ç®—æ¢¯åº¦ï¼ˆå¯¼æ•°ï¼‰çš„æœºåˆ¶

**å¤§ç™½è¯ç†è§£**: 
- æ¢¯åº¦è¡¨ç¤º    å‡½æ•°å˜åŒ–çš„æ–¹å‘å’Œé€Ÿåº¦ 
- åœ¨æœºå™¨å­¦ä¹ ä¸­ç”¨äºä¼˜åŒ–æ¨¡å‹å‚æ•°
- PyTorchè‡ªåŠ¨è·Ÿè¸ªè®¡ç®—è¿‡ç¨‹å¹¶è®¡ç®—æ¢¯åº¦

**ä»£ç ç¤ºä¾‹**:
```python
# è‡ªåŠ¨å¾®åˆ†ç¤ºä¾‹
x = torch.tensor(2.0, requires_grad=True)  # éœ€è¦è®¡ç®—æ¢¯åº¦

# å®šä¹‰ä¸€ä¸ªå‡½æ•° y = x^2 + 3x + 1
y = x**2 + 3*x + 1

# è®¡ç®—æ¢¯åº¦
y.backward()  # è‡ªåŠ¨è®¡ç®—dy/dx

print(f"x = {x.item()}")
print(f"y = {y.item()}")  
print(f"æ¢¯åº¦ dy/dx = {x.grad.item()}")  # åº”è¯¥æ˜¯ 2*2 + 3 = 7
```

### 3. ç¥ç»ç½‘ç»œæ¨¡å— (nn.Module)
**ä»€ä¹ˆæ˜¯nn.Module**: æ„å»ºç¥ç»ç½‘ç»œçš„åŸºç¡€ç±»

**å¤§ç™½è¯ç†è§£**: 
- å°±åƒä¹é«˜ç§¯æœ¨ï¼Œå¯ä»¥ç»„åˆæˆå¤æ‚ç»“æ„
- æ¯ä¸ªæ¨¡å—è´Ÿè´£ç‰¹å®šçš„è®¡ç®—ä»»åŠ¡
- å¯ä»¥æ–¹ä¾¿åœ°å®šä¹‰å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­

## ğŸ—ï¸ æ„å»ºç®€å•çš„ç¥ç»ç½‘ç»œ

### ç¤ºä¾‹ï¼šæ–‡æœ¬åˆ†ç±»æ¨¡å‹
```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class TextClassifier(nn.Module):
    """
    ç®€å•çš„æ–‡æœ¬åˆ†ç±»æ¨¡å‹
    ç”¨äºç†è§£PyTorchæ¨¡å‹çš„åŸºæœ¬ç»“æ„
    """
    
    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):
        """
        åˆå§‹åŒ–æ¨¡å‹å‚æ•°
        
        å‚æ•°è¯´æ˜:
        - vocab_size: è¯æ±‡è¡¨å¤§å°
        - embedding_dim: è¯å‘é‡ç»´åº¦  
        - hidden_dim: éšè—å±‚ç»´åº¦
        - num_classes: åˆ†ç±»ç±»åˆ«æ•°
        """
        super(TextClassifier, self).__init__()
        
        # è¯åµŒå…¥å±‚ï¼šå°†å•è¯ç´¢å¼•è½¬ä¸ºå‘é‡
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        
        # LSTMå±‚ï¼šå¤„ç†åºåˆ—æ•°æ®
        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)
        
        # å…¨è¿æ¥å±‚ï¼šå°†LSTMè¾“å‡ºè½¬ä¸ºåˆ†ç±»ç»“æœ
        self.fc = nn.Linear(hidden_dim, num_classes)
        
        # Dropoutï¼šé˜²æ­¢è¿‡æ‹Ÿåˆ
        self.dropout = nn.Dropout(0.3)
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­è¿‡ç¨‹
        
        å‚æ•°:
        - x: è¾“å…¥æ–‡æœ¬çš„ç´¢å¼•åºåˆ—
        
        è¿”å›:
        - åˆ†ç±»æ¦‚ç‡
        """
        # 1. è¯åµŒå…¥
        embedded = self.embedding(x)  # [batch_size, seq_len, embedding_dim]
        
        # 2. LSTMå¤„ç†
        lstm_out, (hidden, cell) = self.lstm(embedded)
        
        # 3. å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€
        last_hidden = hidden[-1]  # [batch_size, hidden_dim]
        
        # 4. Dropout
        dropped = self.dropout(last_hidden)
        
        # 5. å…¨è¿æ¥å±‚
        output = self.fc(dropped)  # [batch_size, num_classes]
        
        return output

# ä½¿ç”¨ç¤ºä¾‹
model = TextClassifier(
    vocab_size=10000,    # å‡è®¾è¯æ±‡è¡¨æœ‰10000ä¸ªè¯
    embedding_dim=100,   # è¯å‘é‡ç»´åº¦100
    hidden_dim=128,      # LSTMéšè—å±‚ç»´åº¦128
    num_classes=3        # 3åˆ†ç±»é—®é¢˜ï¼ˆå¦‚æ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰
)

print("æ¨¡å‹ç»“æ„:")
print(model)
```

## ğŸ”§ PyTorchåœ¨æµ‹è¯•å¼€å‘ä¸­çš„åº”ç”¨

### 1. æ¨¡å‹åŠ è½½å’Œæ¨ç†æµ‹è¯•
```python
class ModelTester:
    """
    æ¨¡å‹æµ‹è¯•å·¥å…·ç±»
    ç”¨äºæµ‹è¯•PyTorchæ¨¡å‹çš„æ¨ç†åŠŸèƒ½
    """
    
    def __init__(self, model_path):
        """
        åˆå§‹åŒ–æµ‹è¯•å™¨
        
        å‚æ•°:
        - model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        """
        # åŠ è½½æ¨¡å‹
        self.model = torch.load(model_path)
        self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    
    def test_inference(self, test_inputs):
        """
        æµ‹è¯•æ¨¡å‹æ¨ç†åŠŸèƒ½
        
        å‚æ•°:
        - test_inputs: æµ‹è¯•è¾“å…¥æ•°æ®
        
        è¿”å›:
        - æ¨ç†ç»“æœå’Œæ€§èƒ½æŒ‡æ ‡
        """
        results = []
        
        with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜
            for input_data in test_inputs:
                # è½¬æ¢ä¸ºå¼ é‡
                if isinstance(input_data, list):
                    input_tensor = torch.tensor(input_data)
                else:
                    input_tensor = input_data
                
                # æ·»åŠ batchç»´åº¦ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if input_tensor.dim() == 1:
                    input_tensor = input_tensor.unsqueeze(0)
                
                # æ¨ç†
                start_time = time.time()
                output = self.model(input_tensor)
                end_time = time.time()
                
                # å¤„ç†è¾“å‡º
                if output.dim() > 1:
                    predictions = torch.softmax(output, dim=1)
                    predicted_class = torch.argmax(predictions, dim=1)
                else:
                    predicted_class = (output > 0.5).float()
                
                results.append({
                    'input': input_data,
                    'output': output.tolist(),
                    'prediction': predicted_class.tolist(),
                    'inference_time': end_time - start_time
                })
        
        return results
    
    def benchmark_performance(self, batch_sizes=[1, 8, 16, 32]):
        """
        æ€§èƒ½åŸºå‡†æµ‹è¯•
        
        å‚æ•°:
        - batch_sizes: ä¸åŒçš„æ‰¹æ¬¡å¤§å°
        
        è¿”å›:
        - å„æ‰¹æ¬¡å¤§å°çš„æ€§èƒ½æ•°æ®
        """
        performance_data = {}
        
        for batch_size in batch_sizes:
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            test_data = torch.randn(batch_size, 100)  # å‡è®¾è¾“å…¥ç»´åº¦100
            
            # é¢„çƒ­ï¼ˆé¿å…ç¬¬ä¸€æ¬¡è¿è¡Œè¾ƒæ…¢ï¼‰
            for _ in range(3):
                _ = self.model(test_data)
            
            # æ­£å¼æµ‹è¯•
            times = []
            for _ in range(10):  # è¿è¡Œ10æ¬¡å–å¹³å‡
                start = time.time()
                _ = self.model(test_data)
                end = time.time()
                times.append(end - start)
            
            avg_time = sum(times) / len(times)
            throughput = batch_size / avg_time  # æ¯ç§’å¤„ç†æ ·æœ¬æ•°
            
            performance_data[batch_size] = {
                'avg_inference_time': avg_time,
                'throughput': throughput
            }
        
        return performance_data
```

### 2. ç‰¹å¾æå–å’Œæ•°æ®åˆ†æ
```python
class FeatureAnalyzer:
    """
    ç‰¹å¾åˆ†æå·¥å…·
    ç”¨äºåˆ†ææ¨¡å‹ä¸­é—´å±‚çš„ç‰¹å¾è¡¨ç¤º
    """
    
    def __init__(self, model):
        self.model = model
        self.activations = {}
        
        # æ³¨å†Œé’©å­å‡½æ•°æ¥æ•è·ä¸­é—´å±‚è¾“å‡º
        self._register_hooks()
    
    def _register_hooks(self):
        """æ³¨å†Œé’©å­å‡½æ•°æ¥æ•è·å„å±‚è¾“å‡º"""
        def get_activation(name):
            def hook(model, input, output):
                self.activations[name] = output.detach()
            return hook
        
        # ä¸ºæ„Ÿå…´è¶£çš„å±‚æ³¨å†Œé’©å­
        self.model.embedding.register_forward_hook(get_activation('embedding'))
        self.model.lstm.register_forward_hook(get_activation('lstm'))
        self.model.fc.register_forward_hook(get_activation('fc'))
    
    def analyze_features(self, input_data):
        """åˆ†æè¾“å…¥æ•°æ®çš„ç‰¹å¾è¡¨ç¤º"""
        self.activations.clear()  # æ¸…ç©ºä¹‹å‰çš„æ¿€æ´»å€¼
        
        with torch.no_grad():
            _ = self.model(input_data)
        
        analysis = {}
        for layer_name, activation in self.activations.items():
            analysis[layer_name] = {
                'shape': activation.shape,
                'mean': activation.mean().item(),
                'std': activation.std().item(),
                'min': activation.min().item(),
                'max': activation.max().item()
            }
        
        return analysis
```

## ğŸ¯ æµ‹è¯•å¼€å‘å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹ï¼šæƒ…æ„Ÿåˆ†ææ¨¡å‹æµ‹è¯•
```python
class SentimentModelTester:
    """
    æƒ…æ„Ÿåˆ†ææ¨¡å‹æµ‹è¯•ç±»
    ç»¼åˆåº”ç”¨PyTorchè¿›è¡Œæ¨¡å‹æµ‹è¯•
    """
    
    def __init__(self, model, tokenizer):
        self.model = model
        self.tokenizer = tokenizer
    
    def test_sentiment_analysis(self, test_cases):
        """
        æµ‹è¯•æƒ…æ„Ÿåˆ†æåŠŸèƒ½
        
        å‚æ•°:
        - test_cases: æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨ï¼Œæ¯ä¸ªç”¨ä¾‹åŒ…å«æ–‡æœ¬å’ŒæœŸæœ›æƒ…æ„Ÿ
        """
        results = []
        
        for i, test_case in enumerate(test_cases):
            text = test_case['text']
            expected_sentiment = test_case['expected_sentiment']
            
            # æ–‡æœ¬é¢„å¤„ç†
            inputs = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True)
            
            # æ¨¡å‹æ¨ç†
            with torch.no_grad():
                outputs = self.model(**inputs)
                probabilities = torch.softmax(outputs.logits, dim=1)
                predicted_class = torch.argmax(probabilities, dim=1).item()
            
            # æƒ…æ„Ÿæ ‡ç­¾æ˜ å°„ï¼ˆå‡è®¾ï¼š0-è´Ÿé¢ï¼Œ1-ä¸­æ€§ï¼Œ2-æ­£é¢ï¼‰
            sentiment_labels = ['è´Ÿé¢', 'ä¸­æ€§', 'æ­£é¢']
            predicted_sentiment = sentiment_labels[predicted_class]
            
            # åˆ¤æ–­æ˜¯å¦æ­£ç¡®
            is_correct = (predicted_sentiment == expected_sentiment)
            
            results.append({
                'test_id': i,
                'text': text,
                'expected': expected_sentiment,
                'predicted': predicted_sentiment,
                'confidence': probabilities.max().item(),
                'is_correct': is_correct,
                'probabilities': probabilities.tolist()[0]
            })
        
        return results
    
    def calculate_metrics(self, results):
        """è®¡ç®—è¯„æµ‹æŒ‡æ ‡"""
        correct_count = sum(1 for r in results if r['is_correct'])
        accuracy = correct_count / len(results)
        
        # æŒ‰æƒ…æ„Ÿç±»åˆ«ç»Ÿè®¡
        sentiment_stats = {}
        for sentiment in ['è´Ÿé¢', 'ä¸­æ€§', 'æ­£é¢']:
            sentiment_cases = [r for r in results if r['expected'] == sentiment]
            if sentiment_cases:
                correct = sum(1 for r in sentiment_cases if r['is_correct'])
                sentiment_stats[sentiment] = {
                    'total': len(sentiment_cases),
                    'correct': correct,
                    'accuracy': correct / len(sentiment_cases)
                }
        
        return {
            'overall_accuracy': accuracy,
            'sentiment_stats': sentiment_stats,
            'total_tests': len(results)
        }
```

## ğŸ’¡ å­¦ä¹ å»ºè®®å’Œæœ€ä½³å®è·µ

### å­¦ä¹ è·¯å¾„
1. **åŸºç¡€è¯­æ³•**: å¼ é‡æ“ä½œã€è‡ªåŠ¨å¾®åˆ†
2. **æ¨¡å‹æ„å»º**: nn.Moduleçš„ä½¿ç”¨
3. **æ•°æ®å¤„ç†**: Datasetå’ŒDataLoader
4. **è®­ç»ƒæµç¨‹**: ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°
5. **é«˜çº§ç‰¹æ€§**: åˆ†å¸ƒå¼è®­ç»ƒã€æ¨¡å‹éƒ¨ç½²

### æµ‹è¯•å¼€å‘ç‰¹åˆ«å…³æ³¨ç‚¹
1. **æ¨¡å‹çŠ¶æ€ç®¡ç†**: train() vs eval()æ¨¡å¼
2. **å†…å­˜ä¼˜åŒ–**: with torch.no_grad()çš„ä½¿ç”¨
3. **æ‰¹é‡å¤„ç†**: ç†è§£batchç»´åº¦çš„ä½œç”¨
4. **è®¾å¤‡ç®¡ç†**: CPU/GPUæ•°æ®è½¬ç§»

### è°ƒè¯•æŠ€å·§
1. **æ¢¯åº¦æ£€æŸ¥**: ä½¿ç”¨`x.grad`æŸ¥çœ‹æ¢¯åº¦
2. **å½¢çŠ¶è°ƒè¯•**: ç»å¸¸æ£€æŸ¥å¼ é‡å½¢çŠ¶
3. **è®¾å¤‡ç¡®è®¤**: ç¡®ä¿æ•°æ®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
4. **æ•°å€¼ç¨³å®šæ€§**: æ£€æŸ¥NaNå’ŒInfå€¼

## ğŸ”„ ä¸‹ä¸€æ­¥å­¦ä¹ å»ºè®®

1. **å®è·µç»ƒä¹ **: å°è¯•è¿è¡Œä¸Šé¢çš„ä»£ç ç¤ºä¾‹
2. **å®˜æ–¹æ•™ç¨‹**: å®ŒæˆPyTorchå®˜æ–¹æ•™ç¨‹
3. **é¡¹ç›®å®æˆ˜**: å‚ä¸å®é™…çš„æ¨¡å‹æµ‹è¯•é¡¹ç›®
4. **æ·±å…¥åŸç†**: å­¦ä¹ [[æ·±åº¦å­¦ä¹ åŸºæœ¬åŸç†]]

---
**æ ‡ç­¾**: #PyTorch #æ·±åº¦å­¦ä¹  #AIæµ‹è¯• #å·¥å…·ä½¿ç”¨ #å®æˆ˜æŒ‡å—