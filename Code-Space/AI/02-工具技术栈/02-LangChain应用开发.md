# ğŸ”— LangChainåº”ç”¨å¼€å‘æŒ‡å—

## ğŸ“– æœ¬ç« å¯¼è¯»
LangChainæ˜¯æ„å»ºå¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„ä¸»æµæ¡†æ¶ï¼Œä½œä¸ºAIæµ‹è¯•å¼€å‘å·¥ç¨‹å¸ˆï¼ŒæŒæ¡LangChainèƒ½å¸®åŠ©ä½ æ›´å¥½åœ°æµ‹è¯•å’Œè¯„ä¼°AIåº”ç”¨ã€‚æœ¬ç« å°†é‡ç‚¹ä»‹ç»LangChainåœ¨æµ‹è¯•å¼€å‘ä¸­çš„åº”ç”¨ã€‚

## ğŸ¯ ä¸ºä»€ä¹ˆæµ‹è¯•å·¥ç¨‹å¸ˆéœ€è¦å­¦LangChainï¼Ÿ

### LangChainåœ¨AIåº”ç”¨ä¸­çš„è§’è‰²

| ç»„ä»¶ | ä½œç”¨ | æµ‹è¯•å…³æ³¨ç‚¹ |
|------|------|-----------|
| Chains | ç»„åˆå¤šä¸ªLLMè°ƒç”¨ | é“¾å¼è°ƒç”¨çš„æ­£ç¡®æ€§ |
| Agents | æ™ºèƒ½å†³ç­–å’Œå·¥å…·è°ƒç”¨ | å†³ç­–é€»è¾‘å’Œå·¥å…·ä½¿ç”¨ |
| Prompts | æ¨¡æ¿åŒ–æç¤ºè¯ | æç¤ºè¯çš„æœ‰æ•ˆæ€§ |
| Memory | å¯¹è¯è®°å¿†ç®¡ç† | ä¸Šä¸‹æ–‡ä¸€è‡´æ€§ |

### å…·ä½“åº”ç”¨ä»·å€¼
1. **æµ‹è¯•åœºæ™¯æ„å»º**: å¿«é€Ÿæ„å»ºå¤æ‚çš„æµ‹è¯•ç”¨ä¾‹
2. **è‡ªåŠ¨åŒ–è¯„æµ‹**: åˆ©ç”¨Chainå®ç°ç«¯åˆ°ç«¯æµ‹è¯•
3. **å·¥å…·é›†æˆæµ‹è¯•**: æµ‹è¯•Agentçš„å·¥å…·è°ƒç”¨èƒ½åŠ›
4. **æç¤ºè¯ä¼˜åŒ–**: è¯„ä¼°ä¸åŒæç¤ºè¯çš„æ•ˆæœ

## ğŸ§© LangChainæ ¸å¿ƒæ¦‚å¿µ

### 1. Chainï¼ˆé“¾ï¼‰
**ä»€ä¹ˆæ˜¯Chain**: å°†å¤šä¸ªLLMè°ƒç”¨å’Œå·¥å…·ç»„åˆæˆå·¥ä½œæµ

**å¤§ç™½è¯ç†è§£**: 
- å°±åƒ"æµæ°´çº¿"ï¼Œæ¯ä¸ªç¯èŠ‚å¤„ç†ç‰¹å®šä»»åŠ¡
- å¯ä»¥ä¸²è”å¤šä¸ªæ¨¡å‹å’Œå·¥å…·
- å®ç°å¤æ‚çš„å¤šæ­¥æ¨ç†

**ä»£ç ç¤ºä¾‹**:
```python
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.llms import OpenAI

# åˆ›å»ºæç¤ºè¯æ¨¡æ¿
prompt_template = PromptTemplate(
    input_variables=["product", "features"],
    template="""
    è¯·ä¸ºä»¥ä¸‹äº§å“ç¼–å†™ä¸€æ®µè¥é”€æ–‡æ¡ˆï¼š
    äº§å“åç§°ï¼š{product}
    ä¸»è¦ç‰¹ç‚¹ï¼š{features}
    
    æ–‡æ¡ˆè¦æ±‚ï¼š
    1. çªå‡ºäº§å“ä¼˜åŠ¿
    2. å¸å¼•ç›®æ ‡å®¢æˆ·
    3. è¯­è¨€ç”ŸåŠ¨æœ‰è¶£
    """
)

# åˆ›å»ºLLMå®ä¾‹
llm = OpenAI(temperature=0.7)

# åˆ›å»ºChain
marketing_chain = LLMChain(llm=llm, prompt=prompt_template)

# ä½¿ç”¨Chain
result = marketing_chain.run({
    "product": "æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹",
    "features": "è¯­éŸ³è¯†åˆ«å‡†ç¡®ã€å“åº”å¿«é€Ÿã€å¤šè¯­è¨€æ”¯æŒ"
})

print("ç”Ÿæˆçš„è¥é”€æ–‡æ¡ˆ:")
print(result)
```

### 2. Agentï¼ˆæ™ºèƒ½ä½“ï¼‰
**ä»€ä¹ˆæ˜¯Agent**: èƒ½å¤Ÿä½¿ç”¨å·¥å…·è¿›è¡Œå†³ç­–çš„æ™ºèƒ½ç³»ç»Ÿ

**å¤§ç™½è¯ç†è§£**: 
- å°±åƒ"æ™ºèƒ½åŠ©æ‰‹"ï¼Œå¯ä»¥è°ƒç”¨å„ç§å·¥å…·
- æ ¹æ®ä»»åŠ¡éœ€æ±‚è‡ªä¸»é€‰æ‹©å·¥å…·
- å®ç°å¤æ‚çš„é—®é¢˜è§£å†³

**ä»£ç ç¤ºä¾‹**:
```python
from langchain.agents import initialize_agent, Tool
from langchain.agents import AgentType
from langchain.llms import OpenAI

# å®šä¹‰å·¥å…·å‡½æ•°
def search_product_info(query):
    """æœç´¢äº§å“ä¿¡æ¯ï¼ˆæ¨¡æ‹Ÿå‡½æ•°ï¼‰"""
    # è¿™é‡Œå¯ä»¥é›†æˆå®é™…çš„æœç´¢API
    return f"æ‰¾åˆ°å…³äº'{query}'çš„äº§å“ä¿¡æ¯ï¼šé«˜æ€§èƒ½ã€æ˜“ç”¨æ€§å¼º"

def calculate_price(details):
    """è®¡ç®—ä»·æ ¼ï¼ˆæ¨¡æ‹Ÿå‡½æ•°ï¼‰"""
    return "æ ¹æ®é…ç½®è®¡ç®—ï¼Œä»·æ ¼çº¦ä¸º5000å…ƒ"

# åˆ›å»ºå·¥å…·åˆ—è¡¨
tools = [
    Tool(
        name="äº§å“æœç´¢",
        func=search_product_info,
        description="ç”¨äºæœç´¢äº§å“è¯¦ç»†ä¿¡æ¯çš„å·¥å…·"
    ),
    Tool(
        name="ä»·æ ¼è®¡ç®—", 
        func=calculate_price,
        description="ç”¨äºè®¡ç®—äº§å“ä»·æ ¼çš„å·¥å…·"
    )
]

# åˆ›å»ºAgent
llm = OpenAI(temperature=0)
agent = initialize_agent(
    tools, 
    llm, 
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# ä½¿ç”¨Agentè§£å†³å¤æ‚é—®é¢˜
result = agent.run("å¸®æˆ‘äº†è§£æ™ºèƒ½éŸ³ç®±çš„äº§å“ä¿¡æ¯å¹¶è®¡ç®—ä»·æ ¼")
print(result)
```

### 3. Memoryï¼ˆè®°å¿†ï¼‰
**ä»€ä¹ˆæ˜¯Memory**: ç®¡ç†å¯¹è¯å†å²å’Œä¸Šä¸‹æ–‡ä¿¡æ¯

**å¤§ç™½è¯ç†è§£**: 
- å°±åƒ"å¯¹è¯è®°å¿†"ï¼Œè®°ä½ä¹‹å‰çš„äº¤æµå†…å®¹
- å®ç°å¤šè½®å¯¹è¯çš„è¿è´¯æ€§
- é¿å…é‡å¤æé—®å’Œå›ç­”

## ğŸ”§ LangChainåœ¨æµ‹è¯•å¼€å‘ä¸­çš„åº”ç”¨

### 1. è‡ªåŠ¨åŒ–æµ‹è¯•æ¡†æ¶
```python
import asyncio
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.schema import BaseOutputParser

class TestResultParser(BaseOutputParser):
    """æµ‹è¯•ç»“æœè§£æå™¨"""
    
    def parse(self, text: str):
        """
        è§£ææ¨¡å‹è¾“å‡ºçš„æµ‹è¯•ç»“æœ
        
        å‚æ•°:
        - text: æ¨¡å‹è¾“å‡ºçš„æ–‡æœ¬
        
        è¿”å›:
        - ç»“æ„åŒ–çš„æµ‹è¯•ç»“æœ
        """
        # è§£æPASS/FAILç­‰å…³é”®è¯
        if "PASS" in text.upper():
            return {"status": "PASS", "details": text}
        elif "FAIL" in text.upper():
            return {"status": "FAIL", "details": text}
        else:
            return {"status": "UNCLEAR", "details": text}

class AutomatedTester:
    """
    è‡ªåŠ¨åŒ–æµ‹è¯•å™¨
    ä½¿ç”¨LangChainæ„å»ºæ™ºèƒ½æµ‹è¯•ç³»ç»Ÿ
    """
    
    def __init__(self, llm):
        self.llm = llm
        self.parser = TestResultParser()
        
        # åˆ›å»ºæµ‹è¯•Chain
        self.test_chain = self._create_test_chain()
    
    def _create_test_chain(self):
        """åˆ›å»ºæµ‹è¯•Chain"""
        prompt = PromptTemplate(
            input_variables=["test_case", "model_response"],
            template="""
            è¯·è¯„ä¼°ä»¥ä¸‹AIæ¨¡å‹çš„å›ç­”è´¨é‡ï¼š
            
            æµ‹è¯•ç”¨ä¾‹ï¼š{test_case}
            æ¨¡å‹å›ç­”ï¼š{model_response}
            
            è¯„ä¼°æ ‡å‡†ï¼š
            1. ç›¸å…³æ€§ï¼šå›ç­”æ˜¯å¦ä¸é—®é¢˜ç›¸å…³
            2. å‡†ç¡®æ€§ï¼šä¿¡æ¯æ˜¯å¦å‡†ç¡®æ— è¯¯  
            3. å®Œæ•´æ€§ï¼šæ˜¯å¦å…¨é¢å›ç­”é—®é¢˜
            4. å®‰å…¨æ€§ï¼šå†…å®¹æ˜¯å¦å®‰å…¨åˆè§„
            
            è¯·ç»™å‡ºè¯„ä¼°ç»“æœï¼ˆPASS/FAILï¼‰å¹¶è¯´æ˜åŸå› ã€‚
            """
        )
        
        return LLMChain(llm=self.llm, prompt=prompt)
    
    async def run_test_suite(self, test_cases, model_under_test):
        """
        è¿è¡Œæµ‹è¯•å¥—ä»¶
        
        å‚æ•°:
        - test_cases: æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
        - model_under_test: è¢«æµ‹è¯•çš„æ¨¡å‹
        
        è¿”å›:
        - æµ‹è¯•ç»“æœç»Ÿè®¡
        """
        results = []
        
        for i, test_case in enumerate(test_cases):
            print(f"è¿è¡Œæµ‹è¯•ç”¨ä¾‹ {i+1}/{len(test_cases)}: {test_case}")
            
            # è°ƒç”¨è¢«æµ‹è¯•æ¨¡å‹
            model_response = await model_under_test.generate(test_case)
            
            # ä½¿ç”¨LangChainè¯„ä¼°å›ç­”è´¨é‡
            evaluation = self.test_chain.run({
                "test_case": test_case,
                "model_response": model_response
            })
            
            # è§£æè¯„ä¼°ç»“æœ
            parsed_result = self.parser.parse(evaluation)
            parsed_result.update({
                "test_case": test_case,
                "model_response": model_response,
                "evaluation_raw": evaluation
            })
            
            results.append(parsed_result)
            
            # æ·»åŠ å»¶è¿Ÿé¿å…é€Ÿç‡é™åˆ¶
            await asyncio.sleep(1)
        
        return self._analyze_results(results)
    
    def _analyze_results(self, results):
        """åˆ†ææµ‹è¯•ç»“æœ"""
        pass_count = sum(1 for r in results if r["status"] == "PASS")
        fail_count = sum(1 for r in results if r["status"] == "FAIL")
        unclear_count = len(results) - pass_count - fail_count
        
        return {
            "summary": {
                "total_tests": len(results),
                "passed": pass_count,
                "failed": fail_count,
                "unclear": unclear_count,
                "pass_rate": pass_count / len(results)
            },
            "detailed_results": results
        }
```

### 2. æ™ºèƒ½æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ
```python
class TestCaseGenerator:
    """
    æ™ºèƒ½æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨
    ä½¿ç”¨LangChainè‡ªåŠ¨ç”Ÿæˆå¤šæ ·åŒ–çš„æµ‹è¯•ç”¨ä¾‹
    """
    
    def __init__(self, llm):
        self.llm = llm
        
        # åˆ›å»ºä¸åŒç±»å‹çš„æµ‹è¯•ç”¨ä¾‹ç”ŸæˆChain
        self.chains = {
            "functional": self._create_functional_chain(),
            "safety": self._create_safety_chain(),
            "edge_case": self._create_edge_case_chain()
        }
    
    def _create_functional_chain(self):
        """åˆ›å»ºåŠŸèƒ½æµ‹è¯•ç”¨ä¾‹ç”ŸæˆChain"""
        prompt = PromptTemplate(
            input_variables=["domain", "count"],
            template="""
            è¯·ä¸º{domain}é¢†åŸŸçš„AIåŠ©æ‰‹ç”Ÿæˆ{count}ä¸ªåŠŸèƒ½æµ‹è¯•ç”¨ä¾‹ã€‚
            
            è¦æ±‚ï¼š
            1. è¦†ç›–ä¸åŒçš„ç”¨æˆ·åœºæ™¯
            2. åŒ…å«æ˜ç¡®çš„æœŸæœ›ç»“æœ
            3. ç”¨ä¾‹ä¹‹é—´è¦æœ‰å·®å¼‚æ€§
            
            æ ¼å¼ï¼š
            ç”¨ä¾‹1: [é—®é¢˜æè¿°] | [æœŸæœ›å›ç­”è¦ç‚¹]
            ç”¨ä¾‹2: [é—®é¢˜æè¿°] | [æœŸæœ›å›ç­”è¦ç‚¹]
            ...
            """
        )
        return LLMChain(llm=self.llm, prompt=prompt)
    
    def generate_test_cases(self, domain, count=10, test_type="functional"):
        """ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹"""
        chain = self.chains.get(test_type, self.chains["functional"])
        
        result = chain.run({
            "domain": domain,
            "count": count
        })
        
        return self._parse_test_cases(result)
    
    def _parse_test_cases(self, text):
        """è§£æç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹"""
        cases = []
        lines = text.strip().split('\n')
        
        for line in lines:
            if ':' in line and '|' in line:
                # è§£ææ ¼å¼: "ç”¨ä¾‹X: é—®é¢˜ | æœŸæœ›"
                parts = line.split(':', 1)[1].split('|', 1)
                if len(parts) == 2:
                    cases.append({
                        "question": parts[0].strip(),
                        "expected": parts[1].strip()
                    })
        
        return cases
```

### 3. å¤šè½®å¯¹è¯æµ‹è¯•
```python
from langchain.memory import ConversationBufferMemory

class MultiTurnTester:
    """
    å¤šè½®å¯¹è¯æµ‹è¯•å™¨
    æµ‹è¯•æ¨¡å‹åœ¨è¿ç»­å¯¹è¯ä¸­çš„è¡¨ç°
    """
    
    def __init__(self, llm):
        self.memory = ConversationBufferMemory()
        
        # åˆ›å»ºå¸¦è®°å¿†çš„Chain
        self.conversation_chain = self._create_conversation_chain(llm)
    
    def _create_conversation_chain(self, llm):
        """åˆ›å»ºå¯¹è¯Chain"""
        prompt = PromptTemplate(
            input_variables=["history", "input"],
            template="""
            ä»¥ä¸‹æ˜¯å¯¹è¯å†å²ï¼š
            {history}
            
            ç”¨æˆ·æœ€æ–°è¾“å…¥ï¼š{input}
            
            è¯·æ ¹æ®å¯¹è¯å†å²å›åº”ç”¨æˆ·çš„æœ€æ–°è¾“å…¥ã€‚
            """
        )
        
        return LLMChain(
            llm=llm,
            prompt=prompt,
            memory=self.memory,
            verbose=True
        )
    
    def test_conversation_flow(self, conversation_flow):
        """
        æµ‹è¯•å¯¹è¯æµç¨‹
        
        å‚æ•°:
        - conversation_flow: å¯¹è¯æµç¨‹å®šä¹‰
        """
        results = []
        
        for turn in conversation_flow:
            user_input = turn["user"]
            expected_topics = turn.get("expected_topics", [])
            
            # è¿›è¡Œå¯¹è¯
            response = self.conversation_chain.run(input=user_input)
            
            # è¯„ä¼°å›åº”è´¨é‡
            evaluation = self._evaluate_response(
                response, user_input, expected_topics
            )
            
            results.append({
                "turn": len(results) + 1,
                "user_input": user_input,
                "model_response": response,
                "evaluation": evaluation
            })
        
        return results
    
    def _evaluate_response(self, response, user_input, expected_topics):
        """è¯„ä¼°å›åº”è´¨é‡"""
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„è¯„ä¼°é€»è¾‘
        evaluation = {
            "relevance": self._check_relevance(response, user_input),
            "coherence": self._check_coherence(response),
            "topic_coverage": self._check_topic_coverage(response, expected_topics)
        }
        
        return evaluation
```

## ğŸ¯ æµ‹è¯•å¼€å‘å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹ï¼šæ™ºèƒ½å®¢æœç³»ç»Ÿæµ‹è¯•
[^1]
```python
class CustomerServiceTester:
    """
    æ™ºèƒ½å®¢æœç³»ç»Ÿæµ‹è¯•ç±»
    ç»¼åˆåº”ç”¨LangChainè¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•
    """
    
    def __init__(self, customer_service_chain):
        self.customer_service_chain = customer_service_chain
        
        # åŠ è½½æ ‡å‡†æµ‹è¯•ç”¨ä¾‹
        self.standard_test_cases = self._load_standard_cases()
    
    def run_comprehensive_test(self):
        """è¿è¡Œå…¨é¢æµ‹è¯•"""
        test_results = {}
        
        # 1. åŠŸèƒ½æµ‹è¯•
        test_results["functional"] = self._run_functional_tests()
        
        # 2. æ€§èƒ½æµ‹è¯•
        test_results["performance"] = self._run_performance_tests()
        
        # 3. å®‰å…¨æ€§æµ‹è¯•
        test_results["safety"] = self._run_safety_tests()
        
        # 4. ç”¨æˆ·ä½“éªŒæµ‹è¯•
        test_results["user_experience"] = self._run_ux_tests()
        
        return self._generate_test_report(test_results)
    
    def _run_functional_tests(self):
        """è¿è¡ŒåŠŸèƒ½æµ‹è¯•"""
        results = []
        
        for test_case in self.standard_test_cases["functional"]:
            try:
                response = self.customer_service_chain.run(test_case["input"])
                
                # è¯„ä¼°å“åº”è´¨é‡
                is_pass = self._evaluate_functional_response(response, test_case)
                
                results.append({
                    "test_case": test_case["description"],
                    "input": test_case["input"],
                    "response": response,
                    "status": "PASS" if is_pass else "FAIL",
                    "expected": test_case.get("expected", "N/A")
                })
            except Exception as e:
                results.append({
                    "test_case": test_case["description"],
                    "input": test_case["input"],
                    "response": f"ERROR: {str(e)}",
                    "status": "ERROR",
                    "expected": test_case.get("expected", "N/A")
                })
        
        return results
    
    def _evaluate_functional_response(self, response, test_case):
        """è¯„ä¼°åŠŸèƒ½å“åº”"""
        # å®ç°å…·ä½“çš„è¯„ä¼°é€»è¾‘
        # å¯ä»¥åŸºäºå…³é”®è¯åŒ¹é…ã€è¯­ä¹‰ç›¸ä¼¼åº¦ç­‰
        expected_keywords = test_case.get("expected_keywords", [])
        
        if expected_keywords:
            return all(keyword in response for keyword in expected_keywords)
        
        return True  # é»˜è®¤é€šè¿‡
```

## ğŸ’¡ æœ€ä½³å®è·µå’Œæ³¨æ„äº‹é¡¹

### LangChainæµ‹è¯•å¼€å‘æœ€ä½³å®è·µ

1. **æ¨¡å—åŒ–è®¾è®¡**
   ```python
   # å¥½çš„å®è·µï¼šæ¨¡å—åŒ–çš„æµ‹è¯•ç»„ä»¶
   class TestComponent:
       def __init__(self, config):
           self.config = config
           self._initialize_components()
   
   # é¿å…ï¼šæŠŠæ‰€æœ‰é€»è¾‘å†™åœ¨ä¸€ä¸ªå‡½æ•°é‡Œ
   ```

2. **é”™è¯¯å¤„ç†**
   ```python
   # å¥½çš„å®è·µï¼šå®Œå–„çš„é”™è¯¯å¤„ç†
   try:
       result = chain.run(input_data)
   except Exception as e:
       logger.error(f"Chainæ‰§è¡Œå¤±è´¥: {e}")
       return {"status": "ERROR", "error": str(e)}
   ```

3. **é…ç½®ç®¡ç†**
   ```python
   # ä½¿ç”¨é…ç½®æ–‡ä»¶ç®¡ç†æµ‹è¯•å‚æ•°
   TEST_CONFIG = {
       "timeout": 30,
       "retry_count": 3,
       "temperature": 0.1  # æµ‹è¯•æ—¶ä½¿ç”¨è¾ƒä½çš„æ¸©åº¦å€¼
   }
   ```

### æµ‹è¯•ç‰¹åˆ«å…³æ³¨ç‚¹

1. **Chainçš„ç¨³å®šæ€§**: æµ‹è¯•å¤æ‚Chainçš„å¯é æ€§
2. **æç¤ºè¯æœ‰æ•ˆæ€§**: è¯„ä¼°ä¸åŒæç¤ºè¯å¯¹ç»“æœçš„å½±å“
3. **å·¥å…·è°ƒç”¨æ­£ç¡®æ€§**: éªŒè¯Agentå·¥å…·è°ƒç”¨çš„å‡†ç¡®æ€§
4. **è®°å¿†ç®¡ç†**: æµ‹è¯•å¤šè½®å¯¹è¯çš„ä¸Šä¸‹æ–‡ä¸€è‡´æ€§

## ğŸ”„ å­¦ä¹ è·¯å¾„å»ºè®®

### å…¥é—¨é˜¶æ®µï¼ˆ1-2å‘¨ï¼‰
1. å­¦ä¹ LangChainåŸºæœ¬æ¦‚å¿µå’Œç»„ä»¶
2. æŒæ¡Chainçš„åˆ›å»ºå’Œä½¿ç”¨
3. ç†è§£PromptTemplateçš„è®¾è®¡

### è¿›é˜¶é˜¶æ®µï¼ˆ2-4å‘¨ï¼‰
1. å­¦ä¹ Agentå’Œå·¥å…·é›†æˆ
2. æŒæ¡Memoryç®¡ç†
3. å®è·µå¤æ‚çš„åº”ç”¨åœºæ™¯

### ä¸“å®¶é˜¶æ®µï¼ˆ1ä¸ªæœˆ+ï¼‰
1. è‡ªå®šä¹‰ç»„ä»¶å¼€å‘
2. æ€§èƒ½ä¼˜åŒ–å’Œè°ƒè¯•
3. ä¼ä¸šçº§åº”ç”¨éƒ¨ç½²

## ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç¯å¢ƒæ­å»º**: å®‰è£…LangChainå’Œç›¸å…³ä¾èµ–
2. **ç¤ºä¾‹è¿è¡Œ**: å°è¯•è¿è¡Œæœ¬ç« çš„ä»£ç ç¤ºä¾‹
3. **é¡¹ç›®å®è·µ**: å°†LangChainåº”ç”¨åˆ°å®é™…æµ‹è¯•é¡¹ç›®ä¸­
4. **æ·±å…¥åŸç†**: å­¦ä¹ LangChainçš„åº•å±‚å®ç°æœºåˆ¶

---
**æ ‡ç­¾**: #LangChain #AIæµ‹è¯• #åº”ç”¨å¼€å‘ #å·¥å…·ä½¿ç”¨ #å®æˆ˜æŒ‡å—

[^1]: è¶…é“¾æ¥ï¼š[baidu](http://www.baidu.com)