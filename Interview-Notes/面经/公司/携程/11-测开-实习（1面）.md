---
title: "携程-测开-实习（1面）"
---

# 目录

- [一面](#一面)
  - [1. 介绍下在上段实习项目中做的接口自动化测试？做了哪些接口的测试？测试脚本写了多少？有没有去集成测试？让别人用？](#1-介绍下在上段实习项目中做的接口自动化测试做了哪些接口的测试测试脚本写了多少有没有去集成测试让别人用)
  - [2. 测到一个bug怎么办？](#2-测到一个bug怎么办)
  - [3. 怎么测试一个页面？怎么查找问题？](#3-怎么测试一个页面怎么查找问题)
  - [4. 黑盒测试方法？](#4-黑盒测试方法)
  - [5. 兼容性测试方法？](#5-兼容性测试方法)
  - [6. 有没有做过跨组的项目测试？任务怎么分配的？](#6-有没有做过跨组的项目测试任务怎么分配的)
  - [7. 有没有做过WEB端和APP端都有的需求的测试？](#7-有没有做过web端和app端都有的需求的测试)
  - [8. java中堆和队列的区别？](#8-java中堆和队列的区别)
  - [9. 常用的sql操作](#9-常用的sql操作)
  - [10. 开发冒烟自测用例只是主要功能的部分](#10-开发冒烟自测用例只是主要功能的部分)
  - [11. 为什么不投开发？](#11-为什么不投开发)

# 一面

### 1. 介绍下在上段实习项目中做的接口自动化测试？做了哪些接口的测试？测试脚本写了多少？有没有去集成测试？让别人用？

**简短回答：**

**在上段实习中，我主要负责XX系统的订单模块的接口自动化测试。** 我使用了 `Python` + `Pytest` + `Requests` 的技术栈，总共编写了大约50个接口的测试用例，覆盖了订单创建、查询、修改、取消等核心业务流程。这些脚本已经集成到了项目的CI/CD流程中，每次代码提交都会自动触发执行，实现了回归测试的自动化。目前这些脚本主要是由我们测试团队在使用。

**深度回答：**

**在上一段实习中，我完整地参与了XX系统订单模块的接口自动化测试体系建设，从0到1搭建了整个测试流程。**

*   **测试范围和内容：** 我主要负责的是订单服务的核心接口，大概有50多个。测试的重点包括：
    *   **单接口功能测试：** 验证每个接口在正常、异常（如参数错误、权限不足）等情况下的返回是否符合预期。
    *   **业务流程测试：** 将多个接口串联起来，模拟用户的真实操作路径，例如“创建订单 -> 支付 -> 查询订单状态 -> 取消订单”的完整流程，验证业务逻辑的正确性。
    *   **数据一致性校验：** 在关键操作（如创建订单）后，会通过查询数据库或调用其他服务的查询接口，来校验数据的正确性和一致性。
*   **脚本规模与框架：** 我总共编写和维护了超过200个测试用例。在框架方面，我基于 `Pytest` 进行了二次封装，实现了测试数据的分离（使用YAML文件管理测试数据）、日志的统一记录以及测试报告的定制化（集成了`Allure`报告），提高了用例的可维护性和报告的可读性。
*   **集成与应用：**
    *   **CI/CD集成：** 我将自动化测试任务封装成一个独立的Docker镜像，并配置了Jenkins Pipeline。现在，开发同学每次向测试环境合并代码时，都会自动触发一次全量的接口回归测试。如果测试失败，会自动阻塞合并请求并发邮件通知相关人员，实现了测试的“左移”。
    *   **推广使用：** 目前这套自动化测试框架和脚本主要由我们测试组的同学使用。为了方便大家上手，我编写了详细的使用文档，并组织了一次小型的分享会，介绍框架的设计思路和使用方法。我的目标是未来能让开发同学也方便地使用这套框架进行提测前的自测。

> **面试官视角解读：**
>
> *   这个问题旨在考察你的项目经验真实性和技术深度。
> *   回答时，要突出“量化”和“成果”。例如，具体负责了哪个模块、多少个接口、多少个用例，取得了什么效果（如集成CI/CD，提升了多少效率等）。
> *   展示你的“思考”。不仅仅是写脚本，还要说明你如何设计测试框架、如何管理测试数据、如何让测试流程更高效，这能体现你的工程化能力。
> *   说明“有没有让别人用”是考察你的项目是否真正落地并产生了价值，以及你的文档和沟通能力。

### 2. 测到一个bug怎么办？

**简短回答：**

**测到一个Bug后，我会先在本地复现以确认其稳定性，然后使用抓包工具和查看后台日志等方式初步定位问题，最后在Bug管理平台（如Jira）上创建一个包含清晰复现步骤、预期结果和实际结果、以及相关日志截图的Bug单，并指派给对应的开发同学。**

**深度回答：**

**发现一个Bug后，我会遵循一套标准的处理流程，确保问题能够被高效、准确地解决。这个流程可以概括为“复现-定位-报告-跟踪-验证”。**

1.  **复现（Reproduce）：** 这是第一步也是最关键的一步。我会尝试在不同的测试账号、不同的环境下多次复现该Bug，以排除偶发因素。我会记录下详细的复现路径和触发条件。
2.  **定位（Locate）：** 在确认Bug可以稳定复现后，我会进行初步的根源分析。
    *   **前端Bug：** 我会使用浏览器开发者工具，检查DOM结构、CSS样式、网络请求（Request/Response）以及控制台是否有报错信息。
    *   **后端Bug：** 我会通过查看服务日志、数据库数据、甚至使用远程Debug等方式，来判断问题可能出现在哪个模块或哪段逻辑中。
    *   **通过初步定位，我可以将Bug更准确地指派给对应的开发人员，提高修复效率。**
3.  **报告（Report）：** 我会在公司的Bug管理平台（如Jira）上创建一个高质量的Bug报告。一个好的Bug报告应包括：
    *   **一个清晰、概括性的标题。**
    *   **详细、无歧义的复现步骤（Step-by-step）。**
    *   **明确的预期结果（Expected Result）和实际结果（Actual Result）。**
    *   **相关的附件，如截图、录屏、日志文件、抓包数据等。**
    *   **Bug的严重等级（Severity）和优先级（Priority）。**
4.  **跟踪（Track）：** Bug提交后，我会关注其状态流转。如果开发同学对Bug有疑问，我会及时沟通解答。如果Bug被长时间搁置，我会主动提醒相关人员。
5.  **验证（Verify）：** Bug被修复并重新部署到测试环境后，我会第一时间进行回归验证，确保问题已经彻底解决，并且没有引入新的问题（Regression Testing）。验证通过后，我才会关闭该Bug。

> **面试官视角解读：**
>
> *   这个问题考察你作为测试人员的基本素养和工作流程的规范性。
> *   一个好的回答应该是一个结构化、有条理的流程，而不是零散的点。
> *   强调“初步定位”能体现你的技术能力和主动性，你不只是一个“点点点”的测试，而是一个能帮助开发解决问题的合作伙伴。
> *   高质量的Bug报告是测试工程师专业性的重要体现，在回答中突出这一点会很加分。

### 3. 怎么测试一个页面？怎么查找问题？

**简短回答：**

**测试一个页面，我会从功能、UI、性能、兼容性和安全性五个方面入手。** 功能上，我会根据需求文档设计用例，覆盖所有交互逻辑；UI上，保证页面布局、样式和文案的正确性；性能上，关注页面的加载速度和响应时间；兼容性上，测试不同浏览器和分辨率；安全性上，检查是否存在XSS、CSRF等常见漏洞。查找问题时，我会综合使用浏览器开发者工具、抓包工具和查看后端日志等方法。

**深度回答：**

**测试一个Web页面，我会把它看作一个系统性的工程，从上到下、由外到内地进行全面覆盖。**

*   **测试策略与维度：**
    1.  **功能测试（Functionality）：** 这是最核心的部分。我会依据PRD（产品需求文档）和UI设计稿，使用等价类、边界值、场景法等设计测试用例，覆盖所有用户交互和业务逻辑。例如，对于一个登录页面，我会测试：
        *   正确的用户名密码能否登录成功。
        *   错误的用户名或密码能否给出正确提示。
        *   输入框的长度、特殊字符限制。
        *   “记住我”功能是否生效。
        *   多次登录失败后账号是否会被锁定。
    2.  **UI/UX测试（UI/User Experience）：** 我会检查页面的视觉呈现和用户体验是否达标。
        *   **布局和样式：** 页面元素是否对齐，颜色、字体、间距是否与设计稿一致。
        *   **文案：** 页面上的所有静态和动态文案是否准确、无错别字。
        *   **交互体验：** 按钮的点击反馈、加载动画、页面的跳转逻辑是否流畅自然。
    3.  **性能测试（Performance）：** 我会关注页面的响应速度。
        *   **前端性能：** 使用Lighthouse、WebPageTest等工具，分析页面的首次内容绘制（FCP）、最大内容绘制（LCP）、可交互时间（TTI）等核心指标，并针对性地提出优化建议（如压缩图片、合并JS/CSS文件等）。
        *   **后端性能：** 对于页面加载时触发的API，我会使用JMeter等工具进行压力测试，评估其在高并发下的表现。
    4.  **兼容性测试（Compatibility）：** 我会确保页面在不同环境下表现一致。
        *   **浏览器兼容性：** 在主流浏览器（Chrome, Firefox, Safari, Edge）的不同版本上进行测试。
        *   **分辨率兼容性：** 在多种常见屏幕分辨率下测试页面布局是否正常，是否存在元素重叠或错位。
        *   **操作系统兼容性：** 在Windows和macOS上进行测试。
    5.  **安全性测试（Security）：** 我会进行基本的Web安全检查，例如：
        *   检查是否存在XSS（跨站脚本）漏洞，尝试在输入框提交恶意脚本。
        *   检查是否存在CSRF（跨站请求伪造）风险。
        *   检查敏感信息（如密码）在传输过程中是否加密。
*   **问题定位方法：**
    *   **浏览器开发者工具（F12）是我的第一利器：** `Elements`面板看DOM结构，`Console`看JS报错，`Network`看API请求，`Application`看Cookie和本地存储。
    *   **抓包工具（如Charles, Fiddler）：** 用于拦截和分析HTTP/HTTPS请求，方便修改请求参数进行调试。
    *   **后端日志：** 当怀疑是后端问题时，我会根据请求的trace-id去日志系统中查询相关的服务日志，定位错误根源。

> **面试官视角解读：**
>
> *   这个问题考察你的测试思维的广度和深度。
> *   一个好的回答应该是一个有体系、有组织的测试方案，而不是想到哪说到哪。
> *   将测试分为功能、UI、性能、兼容性、安全等维度，是业界通用的成熟做法，能体现你的专业性。
> *   在每个维度下，举出具体的例子（如登录页面的测试点），能让你的回答更生动、更有说服力。
> *   熟练说出各种问题定位的工具和方法，能证明你具备扎实的实践能力。

### 4. 黑盒测试方法？

**简短回答：**

**我常用的黑盒测试方法主要有等价类划分法、边界值分析法、因果图法、场景法和错误推测法。** 等价类和边界值主要用于处理输入框和数据范围；因果图法用于分析输入条件的组合；场景法用于模拟用户的真实操作流程；错误推测法则是基于经验和直觉，猜测系统可能出错的地方。

**深度回答：**

**黑盒测试是我的核心技能之一，在设计测试用例时，我会根据不同的场景，组合使用多种方法来达到最佳的测试覆盖效果。**

*   **等价类划分法：** 这是最基础也是最重要的方法。我会将无穷的输入数据划分为若干个有限的、有代表性的“等价类”，然后从每个类中选取一个数据作为测试用例。例如，对于一个要求输入1-100整数的输入框，我会将其划分为三个等价类：有效等价类（1-100的整数）、无效等价类（小于1的数）、无效等价类（大于100的数）。
*   **边界值分析法：** 这是对等价类划分法的有效补充。大量的实践证明，程序最容易在边界和边界附近出错。因此，我会重点测试等价类的边界点。对于上面那个例子，我设计的边界值用例会包括：0, 1, 2, 99, 100, 101。
*   **因果图/判定表法：** 当输入条件之间存在复杂的组合关系时，我会使用这种方法。我会先画出因果图，分析输入（原因）和输出（结果）之间的逻辑关系，然后将其转化为一个判定表。根据判定表，我可以设计出覆盖所有规则的测试用例，避免遗漏。例如，一个订单提交的场景，可能同时依赖于“用户是否登录”、“商品是否有库存”、“优惠券是否可用”等多个条件，非常适合用判定表来分析。
*   **场景法（流程分析法）：** 我会把自己想象成一个真实的用户，模拟用户可能的操作流程。我会画出业务流程图，然后将图中的每一条路径都设计成一个测试用例。这种方法能有效地测试业务逻辑的正确性。例如，一个电商购物的场景，我会测试“浏览商品 -> 加入购物车 -> 下单 -> 支付”的主流程，以及“下单后取消订单”、“支付失败”等异常分支流程。
*   **错误推测法：** 这是一种基于经验和直觉的方法。我会根据以往的经验，猜测开发人员在编码时最容易犯错的地方，并针对性地设计测试用例。例如，我会特别关注：
    *   并发操作下的数据一致性问题。
    *   大数量下的处理性能问题。
    *   特殊字符或空值的处理。

> **面试官视角解读：**
>
> *   这个问题考察你对测试理论基础的掌握程度。
> *   不要只是简单地罗列方法名称，而是要清晰地解释每种方法的思想，并举出一个恰当的例子来说明其应用场景。
> *   强调你会“组合使用”多种方法，能体现你思维的灵活性和实践经验的丰富性。
> *   如果你能对每种方法的优缺点和适用场景进行分析，会是一个很大的加分项。

### 5. 兼容性测试方法？

**简短回答：**

**对于兼容性测试，我会主要关注浏览器、操作系统和分辨率这三个维度。** 浏览器方面，我会覆盖Chrome、Firefox、Safari等主流浏览器的最新版本；操作系统方面，会覆盖Windows和macOS；分辨率方面，会覆盖PC端和移动端常见的几种分辨率。测试时，我会重点关注UI布局是否错乱、功能是否可用。对于大规模的兼容性测试，可以借助云测试平台来提高效率。

**深度回答：**

**在进行兼容性测试时，我会制定一个详细的测试矩阵，并结合手动测试和自动化工具来高效地完成。**

*   **确定兼容性范围（测试矩阵）：**
    *   **浏览器：** 根据产品目标用户和市场占有率，我会确定一个浏览器列表。通常会包括：Chrome, Firefox, Safari, Edge的最新1-2个版本。对于一些特殊项目，可能还需要考虑IE11。
    *   **操作系统：** 主要覆盖Windows（如Win10, Win11）和macOS的最新版本。
    *   **分辨率：** 我会选取几种典型的屏幕分辨率进行测试，例如 `1920x1080`, `1440x900`, `1366x768` 等，并特别关注响应式布局在不同分辨率下的表现。
    *   **移动端：** 如果是移动端Web页面，还需要考虑iOS和Android两大操作系统，以及不同品牌的手机（如华为、小米、iPhone）的自带浏览器。
*   **测试方法与策略：**
    1.  **手动测试：** 对于核心业务流程和UI布局复杂的页面，我会进行手动测试。我会准备好多台不同环境的虚拟机或真实设备，逐一进行验证，重点关注UI显示异常（如错位、重叠、截断）、功能不可用（如按钮点击无效、JS报错）等问题。
    2.  **自动化测试：** 对于一些标准化的功能回归，可以编写UI自动化脚本，并借助Selenium Grid等工具，在不同的浏览器和操作系统上并行执行，极大地提高测试效率。
    3.  **云测试平台：** 当需要覆盖大量设备（尤其是移动端）时，我会考虑使用第三方的云测试平台（如Testin、BrowserStack）。这些平台提供了海量的真机和浏览器环境，我们只需要上传我们的测试脚本或APK，就可以快速得到一份详细的兼容性测试报告，成本效益非常高。
*   **问题定位：** 发现兼容性问题后，我会使用对应浏览器的开发者工具进行调试，定位问题是由于CSS样式不兼容还是JS API不支持导致的，并提供给开发人员进行修复。

> **面试官视角解读：**
>
> *   这个问题考察你对兼容性测试的理解和实践经验。
> *   一个好的回答应该从“确定范围”、“测试方法”、“问题定位”三个方面来展开，体现你的系统性思维。
> *   提到“测试矩阵”是一个很专业的术语，会给面试官留下好印象。
> *   知道并能说出“云测试平台”的作用，表明你了解业界的主流测试解决方案，视野比较开阔。

### 6. 有没有做过跨组的项目测试？任务怎么分配的？

**简短回答：**

**在之前的实习中，我参与过一个需要与支付组协作的项目。** 当时我们订单模块需要接入新的支付渠道。任务分配主要是基于模块和职责边界。我负责我们订单模块在调用支付接口前后的所有逻辑验证，而支付组的测试同学则负责支付服务本身的功能和稳定性。我们会共同参与测试方案的评审，并约定好接口的Mock规则和联调时间。

**深度回答：**

**是的，我参与过一个涉及我们业务组、支付组和风控组三个团队的复杂项目。这个经历让我深刻理解了跨团队协作的重要性。**

*   **项目背景：** 我们需要上线一个新的“分期支付”功能，这需要订单系统、支付系统和风控系统进行联动开发。
*   **任务分配与协作模式：**
    1.  **前期：共同评审，明确边界。** 在项目启动初期，我们三个组的PM、开发和测试会一起召开一个需求和方案的评审会。在这个会上，我们会明确每个系统的职责边界和接口协议。作为测试，我会特别关注异常流程和数据流转的定义，例如“风控拒绝后订单状态如何流转”、“支付失败后如何向用户展示”等。
    2.  **中期：分头测试，Mock先行。** 在开发阶段，各个团队会基于定好的接口协议，使用Mock Server进行独立的开发和测试。我负责我们订单模块的所有功能，比如，我会Mock风控接口返回“通过”和“拒绝”两种情况，来验证我们系统的处理逻辑是否正确。
    3.  **后期：集中联调，端到端验证。** 在各个系统都完成单元测试和组件测试后，我们会进入联调阶段。我们会约定一个专门的联调环境和时间，然后由我作为主导，设计端到端（End-to-End）的测试用例，覆盖用户从下单到支付完成的整个链路。在联调过程中发现的问题，我们会建立一个共同的沟通群，快速定位问题是出在哪个环节，并指派给对应的负责人。
*   **我的角色和职责：** 在这个项目中，我不仅要负责我们自己模块的测试，还承担了一部分“沟通桥梁”的角色。我会主动去了解支付和风控系统的测试进度和遇到的问题，并及时同步给我们组的开发同学，确保信息的高效流转。

> **面试官视角解读：**
>
> *   这个问题考察你的沟通能力、协作能力和处理复杂项目经验。
> *   一个好的回答应该能清晰地描述项目的背景、你所扮演的角色、以及你们团队是如何进行协作的。
> *   强调“前期评审”、“中期Mock”、“后期联调”这种分阶段的协作模式，能体现你对复杂项目管理流程的理解。
> *   突出你在其中的主动性，例如“主动沟通”、“作为沟通桥梁”，能塑造你积极、负责的形象。

### 7. 有没有做过WEB端和APP端都有的需求的测试？

**简短回答：**

**做过。之前有一个活动页面，同时在Web端和App端上线。** 测试时，我会特别关注它们之间的差异点。后端接口通常是复用的，我会重点进行接口测试。对于前端，Web端主要关注不同浏览器的兼容性，而App端则需要关注不同手机型号、操作系统版本和网络环境下的表现，比如App的安装、升级、推送、权限等特有功能。

**深度回答：**

**是的，我之前负责过一个“我的优惠券”功能，这个功能在Web端和App端都有入口。在测试这个需求时，我会采用“后端统一测，前端分别测”的策略。**

*   **后端统一测试：**
    *   Web端和App端的核心业务逻辑（如优惠券的查询、使用、过期等）都是由同一套后端API提供服务的。因此，我会将测试的重点放在接口层。我会编写一套完整的接口自动化测试用例，覆盖所有业务规则和异常场景。这部分测试通过后，就意味着核心功能的质量得到了保证，无论前端是Web还是App。
*   **前端差异化测试：**
    *   **Web端测试重点：**
        *   **兼容性：** 如前所述，重点测试不同浏览器（Chrome, Safari等）和不同分辨率下的UI布局和功能表现。
        *   **响应式设计：** 如果页面是响应式的，需要验证在不同窗口大小下，布局是否能正常切换。
    *   **App端测试重点：**
        *   **兼容性：** 重点测试不同操作系统（iOS, Android）、不同手机品牌和型号、不同屏幕尺寸下的UI适配情况。
        *   **App专项测试：** 这是App测试独有的，包括：
            *   **安装、卸载、升级：** 测试App能否正常安装，升级后数据是否丢失。
            *   **网络测试：** 模拟弱网（2G/3G）、网络切换（WiFi -> 4G）等场景，测试App的响应和表现。
            *   **中断测试：** 在使用功能时，突然接到来电、收到短信，测试App能否正常恢复。
            *   **权限测试：** 测试App对相机、通讯录、地理位置等权限的申请和处理是否合规。
        *   **交互方式差异：** App端有更多手势操作（如滑动、缩放），需要进行针对性的测试。

**总结来说，对于这类需求，我会首先通过接口测试保证业务逻辑的统一正确，然后再针对Web和App各自的平台特性，进行差异化的UI和专项测试。**

> **面试官视角解读：**
>
> *   这个问题考察你对不同平台测试特点的理解。
> *   清晰地分离出“后端”和“前端”的测试策略，是一个很好的切入点，能体现你的结构化思维。
> *   在回答中，能详细列出App专项测试（如网络、中断、权限等）的具体内容，是体现你专业性和经验的关键，会非常加分。

### 8. java中堆和队列的区别？

**简短回答：**

**您是指数据结构中的“堆（Heap）”和“队列（Queue）”吗？它们是两种完全不同的数据结构。** 队列是一种“先进先出”（FIFO）的线性数据结构，主要操作是入队和出队。而堆通常指的是一种优先队列，它是一个完全二叉树，分为最大堆和最小堆，其主要特点是父节点的值总是大于（或小于）所有子节点的值，主要操作是插入和删除最大（或最小）值。

**深度回答：**

**这是一个很好的问题，可以从数据结构和内存模型两个角度来理解，但我猜您主要想问的是数据结构中的“堆”和“队列”。**

*   **从数据结构的角度看，它们的核心区别在于逻辑结构和操作特性：**
    *   **队列（Queue）：**
        *   **逻辑结构：** 是一种线性表，元素之间是“一对一”的关系。
        *   **操作原则：** 严格遵循“先进先出”（First-In, First-Out）。就像排队买票，先来的人先买到票。元素只能从队尾（rear）进入，从队头（front）离开。
        *   **主要应用：** 广度优先搜索（BFS）、消息队列、线程池的任务调度等，所有需要按顺序处理任务的场景。
    *   **堆（Heap）：**
        *   **逻辑结构：** 是一种树形结构，具体来说是一个完全二叉树。元素之间是“一对多”的关系。
        *   **操作原则：** 它不关心元素进入的顺序，只关心元素的“优先级”。对于最小堆，堆顶永远是最小的元素；对于最大堆，堆顶永远是最大的元素。它是一种“优先出”（Priority-Out）的结构。
        *   **主要应用：** 主要用于实现优先队列。例如，从1亿个用户中找出最活跃的Top 100用户（使用最小堆）、Dijkstra算法中寻找最短路径、以及堆排序。

*   **如果从Java内存模型的角度看（虽然可能性较小，但可以作为补充）：**
    *   **堆（Heap）：** 是Java虚拟机管理的一块内存区域，用于存放几乎所有的对象实例和数组。它是所有线程共享的，也是垃圾回收（GC）的主要区域。
    *   **队列（Queue）：** 在Java内存模型中没有一个直接对应的区域。`Queue`是`java.util`包下的一个接口，它的实现类（如`LinkedList`, `ArrayBlockingQueue`）所创建的对象实例，是存放在JVM的“堆”内存中的。

**所以，总结一下，数据结构中的“堆”和“队列”是两种用途和原理完全不同的抽象数据类型。而JVM中的“堆”内存，则是存放这些数据结构实例的物理空间。**

> **面试官视角解读：**
>
> *   这个问题可能存在歧义（数据结构 vs JVM内存），先主动向面试官确认“您是指数据结构中的...吗？”，是一个非常好的沟通习惯，能体现你的严谨性。
> *   清晰地从“逻辑结构”、“操作原则”、“主要应用”三个方面对比两者的区别，能展示你扎实的基础知识。
> *   能够补充Java内存模型中的“堆”的概念，并说明它与数据结构“队列”的关系，能极大地拔高你回答的深度，展示你知识体系的完整性。

### 9. 常用的sql操作

**简短回答：**

**我常用的SQL操作主要包括增删改查（CRUD）。** `INSERT`用于插入数据，`DELETE`用于删除数据，`UPDATE`用于更新数据，`SELECT`用于查询数据。在查询时，我还会经常使用`WHERE`进行条件过滤，`JOIN`进行多表连接，`GROUP BY`进行分组统计，以及`ORDER BY`进行排序。

**深度回答：**

**在实习工作中，SQL是我每天都会用到的工具，除了基本的增删改查，我还熟练掌握了一系列用于复杂查询和数据分析的操作。**

*   **数据定义语言 (DDL):**
    *   `CREATE TABLE`: 用于创建新表，定义表的列、数据类型和约束。
    *   `ALTER TABLE`: 用于修改表结构，如添加、删除列或修改列类型。
    *   `DROP TABLE`: 用于删除表。
*   **数据操作语言 (DML) - 增删改:**
    *   `INSERT INTO`: 向表中插入新的行。
    *   `UPDATE ... SET ... WHERE ...`: 更新表中符合条件的数据。
    *   `DELETE FROM ... WHERE ...`: 删除表中符合条件的行。
*   **数据查询语言 (DQL) - 查:** 这是我使用最频繁的部分。
    *   **基本查询:** `SELECT ... FROM ... WHERE ...`
    *   **连接查询:**
        *   `INNER JOIN`: 获取两个表的交集。
        *   `LEFT JOIN` / `RIGHT JOIN`: 获取左表或右表的所有数据，以及与另一个表的交集。
        *   `FULL OUTER JOIN`: 获取两个表的全集。
    *   **分组与聚合:**
        *   `GROUP BY`: 将数据按某个或某些列进行分组。
        *   `COUNT()`, `SUM()`, `AVG()`, `MAX()`, `MIN()`: 常与`GROUP BY`配合使用，进行聚合计算。
        *   `HAVING`: 对`GROUP BY`之后的结果进行过滤。
    *   **排序与分页:**
        *   `ORDER BY ... ASC/DESC`: 对结果集进行升序或降序排序。
        *   `LIMIT ... OFFSET ...`: 用于实现分页查询。
    *   **子查询:** 在一个查询语句中嵌套另一个查询语句，用于处理复杂的逻辑。

**举个例子，在测试订单功能时，我经常需要写这样的SQL来核对数据：查询今天每个用户下了多少个金额大于100元的订单，并按订单数量倒序排列。**

```sql
SELECT 
    user_id, 
    COUNT(order_id) as order_count
FROM 
    orders
WHERE 
    amount > 100
    AND create_time >= '2023-10-27 00:00:00'
GROUP BY 
    user_id
HAVING 
    order_count > 0
ORDER BY 
    order_count DESC;
```

> **面试官视角解读：**
>
> *   这个问题考察你的数据库基础。
> *   不要只回答“增删改查”，这太基础了。一个好的回答应该能体现出你处理复杂查询的能力。
> *   将SQL操作进行分类（DDL, DML, DQL），并详细列出`JOIN`, `GROUP BY`, `HAVING`等关键字，能展示你知识的系统性。
> *   最后，能现场手写一个有一定复杂度的SQL语句作为例子，是证明你“熟练掌握”的最好方式，非常加分。

### 10. 开发冒烟自测用例只是主要功能的部分

**简短回答：**

**是的，我认同这个观点。开发同学的冒烟自测，其主要目的是快速验证本次代码修改没有影响到系统的核心主干流程，保证程序能够跑通。** 而我们测试人员的职责，则是在这个基础上，进行更全面、更深入的测试，包括各种分支流程、异常场景、边界条件以及非功能性的测试。

**深度回答：**

**是的，这句话准确地描述了开发自测和测试人员测试的职责分工。我认为这体现了“测试分层”的思想。**

*   **开发自测（冒烟测试）：**
    *   **目的：** 它的核心目的是“保证可测性”。开发同学在提测前，需要运行一套最核心的冒烟用例，确保本次开发的功能基本可用，并且没有破坏掉系统的其他核心功能。这就像是厨师把菜炒好后，自己先尝一下咸淡，确保味道没问题再端给客人。
    *   **范围：** 通常只覆盖最主要的功能路径（Happy Path），例如，电商应用能正常下单，社交应用能正常发帖。它的特点是“快”，执行时间应该在几分钟之内。
    *   **价值：** 极大地提升了协作效率。它避免了开发提测一个“半成品”甚至“跑不起来”的版本给测试，减少了测试人员发现低级Bug和来回沟通的成本。
*   **测试人员的测试：**
    *   **目的：** 我们的目的是“保证质量”。我们需要站在用户的角度，对软件进行系统性、全方位的质量检验。
    *   **范围：** 我们的测试范围要广泛和深入得多，包括：
        *   **所有功能分支：** 不仅包括主路径，还包括各种次要流程和异常分支。
        *   **数据边界和异常输入：** 使用等价类、边界值等方法，测试各种临界条件。
        *   **非功能性需求：** 如性能、兼容性、安全性、稳定性等。
        *   **用户体验：** 站在用户的角度，评估产品是否好用、易用。

**总而言之，开发自测是保证“代码不出门就基本正确”，而我们的测试是保证“产品交付到用户手上是高质量的”。两者是互补关系，共同构成了软件质量保障体系中重要的一环。**

> **面试官视角解读：**
>
> *   这个问题看似是一个陈述句，实际上是在考察你对测试流程和角色分工的理解。
> *   一个好的回答应该首先表示认同，然后清晰地阐述开发自测和测试人员测试在“目的”、“范围”和“价值”上的区别。
> *   使用“测试分层”或“测试金字塔”等专业术语，能体现你的理论水平。
> *   用一个生动的比喻（如“厨师尝咸淡”）来解释，能让你的回答更易于理解和记忆。

### 11. 为什么不投开发？

**简短回答：**

**因为我发现自己对“保障系统质量和提升研发效率”这件事更感兴趣。** 我之前的开发实习让我打下了很好的技术基础，但我逐渐意识到，相比于实现具体的业务功能，我更享受通过技术手段去发现和预防问题，去构建自动化的体系来守护整个产品的质量。测试开发这个角色能让我更全面地看问题，我觉得更有挑战和成就感。

**深度回答：**

**这个选择是基于我对个人兴趣和职业发展的深入思考，我认为测试开发岗位更符合我的长期目标。**

*   **兴趣驱动：** 在经历了后端开发的实习后，我发现自己虽然能够完成业务功能的开发，但内心深处更大的热情在于“如何让系统更稳定、更可靠”。每当通过自己的努力发现一个隐藏很深的Bug，或者通过搭建自动化流程提升了整个团队的效率时，我获得的成就感远大于完成一个业务需求。我享受那种作为“质量守护者”的感觉。
*   **技术广度与深度：** 我认为优秀的测试开发工程师需要“比开发更懂测试，比测试更懂开发”。这个岗位要求我不仅要具备扎实的开发能力去构建测试工具和平台，还需要具备广阔的测试思维去设计全面的测试方案。同时，为了做好白盒测试、性能测试、安全测试等，我必须深入理解系统的架构、代码的实现、底层协议的原理。这种对技术广度和深度的复合型要求，对我非常有吸引力。
*   **价值体现：** 我认为测试开发的价值是“赋能”和“放大”。一个开发工程师可能主要对某个功能模块负责，而一个测试开发工程师可以通过开发一个高效的测试框架或平台，服务于整个产品线甚至整个公司，将自己的技术能力放大，为整个研发体系的效率和质量做出贡献。这种杠杆效应是我非常看重的。

**所以，我并非排斥开发，恰恰相反，我希望把我对开发的热情和技能，应用到更具挑战和全局视角的测试开发领域中来。**

> **面试官视角解读：**
>
> *   这个问题和HR面中的类似问题目的一样，考察你的求职动机。
> *   切忌说“开发太卷了”、“我开发学得不好”等负面或消极的理由。
> *   一个好的回答应该强调你对测试开发岗位的“正向”兴趣和深刻理解。
> *   从“兴趣”、“技术追求”、“价值体现”等多个角度来阐述，让你的选择看起来是经过深思熟虑的、主动的、积极的。
> *   最后一句“我并非排斥开发...而是希望把开发技能应用到测开领域”是一个很好的总结，它表明你的转型是基于现有优势的升华，而不是对过去的否定。